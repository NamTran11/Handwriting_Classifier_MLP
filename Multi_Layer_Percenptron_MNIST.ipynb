{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mndata = MNIST('samples')\n",
    "\n",
    "def convert_all_label(Labels):\n",
    "    l = len(Labels)\n",
    "    target = np.zeros((10,l),dtype=float)\n",
    "    for i in range(l):\n",
    "        m = Labels[i]\n",
    "        target[m,i] = 1.\n",
    "    return target\n",
    "def convert_a_label(value):\n",
    "    target = np.zeros((10,1),dtype=float)\n",
    "    target[value]=1.\n",
    "    return target\n",
    "def softmax(V):\n",
    "    # tru cho np.max de chống tràn số khi số mũ quá lớn\n",
    "    e_V = np.exp(V - np.max(V, axis = 0, keepdims = True))\n",
    "    Z = e_V / e_V.sum(axis = 0)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, labels_train = mndata.load_training()\n",
    "images_test, labels_test = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(images_train[0],(28,28)),cmap='Greys')\n",
    "convert_a_label(labels_train[0])\n",
    "print(len(images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_output = 10\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 50     #100\n",
    "learning_rate = 0.01\n",
    "N = len(images_train)\n",
    "total_batch = int(N/batch_size) # per loop\n",
    "\n",
    "weights = {\n",
    "    'w1':0.01*np.random.randn(n_input,n_hidden_1),\n",
    "    'w2':0.01*np.random.randn(n_hidden_1,n_hidden_2),\n",
    "    'out':0.01*np.random.randn(n_hidden_2,n_output)\n",
    "}\n",
    "biases = {\n",
    "\n",
    "    'b1':np.zeros((n_hidden_1,1)),\n",
    "    'b2':np.zeros((n_hidden_2,1)),\n",
    "    'out':np.zeros((n_output,1))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training mini-BGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for it in range(training_epochs):\n",
    "    rd_id = np.random.permutation(N)\n",
    "    for i in range(total_batch):\n",
    "        #get batch (100 element random )\n",
    "        X = [images_train[j] for j in rd_id[i*batch_size:(i+1)*batch_size]] #batch_size*784\n",
    "        Y = [labels_train[j] for j in rd_id[i*batch_size:(i+1)*batch_size]] #batch_size*1\n",
    "        Y = convert_all_label(Y) #10*100\n",
    "        \n",
    "        X = np.asarray(X) #batch_size*n_input\n",
    "        Y = np.asarray(Y) #n_output*batch_size\n",
    "        \n",
    "        #caculator L1 L2 L_out\n",
    "        Z1 = np.dot(weights['w1'].T,X.T)+biases['b1']         # n_hidden_1*batch_size\n",
    "        Layer_1 = np.maximum(Z1,0)                            # n_hidden_1*batch_size\n",
    "        Z2 = np.dot(weights['w2'].T,Layer_1)+biases['b2']     # n_hidden_2*batch_size\n",
    "        Layer_2 = np.maximum(Z2,0)                            # n_hidden_2*batch_size\n",
    "        Zout = np.dot(weights['out'].T,Layer_2)+biases['out'] # n_output*batch_size \n",
    "        Yhat = softmax(Zout)                                  # n_output*batch_size\n",
    "        \n",
    "        #  backpropagation\n",
    "        E_out = (Yhat-Y)/batch_size                           # n_output*batch_size\n",
    "        dW_out = np.dot(Layer_2,E_out.T)                      # n_hiddent_2*output\n",
    "        db_out = np.sum(E_out, axis = 1, keepdims = True)     #\n",
    "        \n",
    "        E_2 = np.dot(weights['out'],E_out)                     # n_hiden_2*batch_size\n",
    "        E_2[Layer_2<=0] = 0 # gradient of ReLU\n",
    "        dW_2 = np.dot(Layer_1,E_2.T)\n",
    "        db_2 = np.sum(E_2, axis = 1, keepdims = True)\n",
    "        \n",
    "        E_1 = np.dot(weights['w2'],E_2)                     # n_hiden_1*batch_size\n",
    "        E_1[Layer_1<=0] = 0                                 # gradient of ReLU\n",
    "        dW_1 = np.dot(X.T,E_1.T)                            # n_input*n_hidden_1\n",
    "        db_1 = np.sum(E_1, axis = 1, keepdims = True)       # n_hidden_1\n",
    "        \n",
    "        #update weights and bias\n",
    "        weights['out'] += -learning_rate*dW_out\n",
    "        weights['w2'] += -learning_rate*dW_2\n",
    "        weights['w1'] += -learning_rate*dW_1\n",
    "        biases['out'] += -learning_rate*db_out\n",
    "        biases['b2'] += -learning_rate*db_2\n",
    "        biases['b1'] += -learning_rate*db_1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test, labels_test = mndata.load_testing()\n",
    "#labels_test = np.reshape(labels_test,(10000,1))\n",
    "images_test = np.asarray(images_test)\n",
    "#labels_test = np.asarray(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def testing_sigle_value(temp):\n",
    "    temp = np.asarray(temp)\n",
    "    np.reshape(temp,(784,1))\n",
    "    Z1_temp = np.dot(weights['w1'].T,temp)+biases['b1']#256*784\n",
    "    Layer1_temp = np.maximum(Z1_temp,0)\n",
    "    Z2_temp = np.dot(weights['w2'].T,Layer1_temp)+biases['b2']#256*1\n",
    "    Layer2_temp = np.maximum(Z2_temp,0)\n",
    "    Zout_temp = np.dot(weights['out'].T,Layer2_temp)+biases['out'] #10*1\n",
    "    predict_class = np.argmax(Zout_temp,axis=1)\n",
    "    return Zout_temp\n",
    "\n",
    "#print(images_test[0])\n",
    "#print(labels_test.shape)\n",
    "it = 14\n",
    "k = np.asarray(images_test[it])\n",
    "t = testing_sigle_value(np.reshape(k,(784,1)))\n",
    "print(np.argmax(t,axis=0))\n",
    "print(labels_test[it])\n",
    "#labels_test[0]\n",
    "#labels_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precdic correct  98.63 %\n"
     ]
    }
   ],
   "source": [
    "Z1_temp = np.dot(weights['w1'].T,images_test.T)+biases['b1']\n",
    "Layer1_temp = np.maximum(Z1_temp,0)\n",
    "Z2_temp = np.dot(weights['w2'].T,Layer1_temp)+biases['b2']\n",
    "Layer2_temp = np.maximum(Z2_temp,0)\n",
    "Zout_temp = np.dot(weights['out'].T,Layer2_temp)+biases['out']\n",
    "predict_class = np.argmax(Zout_temp,axis=0)\n",
    "acc = (100*np.mean(predict_class==labels_test))\n",
    "print('precdic correct  %.2f %%' % acc )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = {'weights':weights,'biases':biases}\n",
    "pickle_write = open(\"data.pkl\",\"wb\")\n",
    "pickle.dump(data,pickle_write)\n",
    "pickle_write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([9, 4, 4, 3, 3, 9, 0, 4, 6, 0])\n",
    "ind = np.argpartition(a, -2)[-2:]\n",
    "ind[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
